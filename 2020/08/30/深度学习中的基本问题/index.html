<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning," />










<meta name="description" content="一、常用的激活函数激活函数一般用于神经网络的层与层之间，将上一层的输出转换之后输入到下一层。如果没有激活函数引入的非线性特性，那么神经网络就只相当于原始感知机的矩阵相乘激活函数分为线性激活函数和非线性激活函数。 为什么需要非线性的激活函数：神经网络用于实现复杂的函数，而 非线性激活函数能够使神经网络逼近任意复杂的函数。如果没有激活函数引入的非线性，多层神经网络就相当于单层的神经网络。常用的非线性激">
<meta name="keywords" content="Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习中的基本问题总结">
<meta property="og:url" content="http://yoursite.com/2020/08/30/深度学习中的基本问题/index.html">
<meta property="og:site_name" content="Welcome Hexo">
<meta property="og:description" content="一、常用的激活函数激活函数一般用于神经网络的层与层之间，将上一层的输出转换之后输入到下一层。如果没有激活函数引入的非线性特性，那么神经网络就只相当于原始感知机的矩阵相乘激活函数分为线性激活函数和非线性激活函数。 为什么需要非线性的激活函数：神经网络用于实现复杂的函数，而 非线性激活函数能够使神经网络逼近任意复杂的函数。如果没有激活函数引入的非线性，多层神经网络就相当于单层的神经网络。常用的非线性激">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2020/08/30/NEtnpfRKQUYsCJ7.gif">
<meta property="og:image" content="https://i.loli.net/2020/08/30/qdMyYbTGVvPteXn.png">
<meta property="og:image" content="https://i.loli.net/2020/08/30/U8r5kZC6zoxOsJD.png">
<meta property="og:image" content="https://i.loli.net/2020/08/30/poTEfgAb2wi6z1e.png">
<meta property="og:image" content="https://i.loli.net/2020/08/30/AVC16sm5rzx9Pij.gif">
<meta property="og:image" content="https://i.loli.net/2020/08/30/EgxudmY3SzCPZsi.png">
<meta property="og:image" content="https://i.loli.net/2020/08/30/dbxKNlqBsIozXyh.png">
<meta property="og:image" content="https://i.loli.net/2020/08/31/12hWOjQLGVJs45v.png">
<meta property="og:image" content="https://i.loli.net/2020/08/31/pq2XEfF9NebSVA6.png">
<meta property="og:image" content="https://i.loli.net/2020/08/31/Cx7B4Ajdn5esISO.jpg">
<meta property="og:image" content="https://i.loli.net/2020/08/31/6FW2U7H4YDA5vjx.jpg">
<meta property="og:image" content="https://i.loli.net/2020/08/31/NSEPmsz3t9DlLVR.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/01/upy9Tr4ImUO3Sht.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/01/Fe4pAbNzEXuPmxQ.png">
<meta property="og:image" content="https://i.loli.net/2020/09/02/MTROQX4E8se62q9.png">
<meta property="og:image" content="https://i.loli.net/2020/09/02/YfUyPA7RJSDETlG.png">
<meta property="og:image" content="https://i.loli.net/2020/09/02/B3YTswv6rIRmkgx.png">
<meta property="og:image" content="https://i.loli.net/2020/09/02/awIjbMrRfnByQHh.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/DkGuIAbhUWjrgax.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/EC3GuotRWnf21cg.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/L379Uox5RwaBqN8.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/fIHqC2zTM7x5wPS.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/28L71Nvd3e49ruW.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/UW9ZKE6VrIxFeGH.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/2lBrUymeFPhcOZx.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/kmWcP7lV4tXRCrU.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/XsW42vmVzyZFauj.jpg">
<meta property="og:image" content="https://i.loli.net/2020/09/02/NHEPoCLqW4VkUKv.jpg">
<meta property="og:updated_time" content="2020-09-02T13:24:42.903Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习中的基本问题总结">
<meta name="twitter:description" content="一、常用的激活函数激活函数一般用于神经网络的层与层之间，将上一层的输出转换之后输入到下一层。如果没有激活函数引入的非线性特性，那么神经网络就只相当于原始感知机的矩阵相乘激活函数分为线性激活函数和非线性激活函数。 为什么需要非线性的激活函数：神经网络用于实现复杂的函数，而 非线性激活函数能够使神经网络逼近任意复杂的函数。如果没有激活函数引入的非线性，多层神经网络就相当于单层的神经网络。常用的非线性激">
<meta name="twitter:image" content="https://i.loli.net/2020/08/30/NEtnpfRKQUYsCJ7.gif">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/08/30/深度学习中的基本问题/"/>





  <title>深度学习中的基本问题总结 | Welcome Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	
	<a href="https://github.com/guolipa" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    
	<header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Welcome Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Adventure Of Lifetime</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/30/深度学习中的基本问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="guoLipa">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习中的基本问题总结</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-30T21:02:18+08:00">
                2020-08-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="一、常用的激活函数"><a href="#一、常用的激活函数" class="headerlink" title="一、常用的激活函数"></a>一、常用的激活函数</h1><p>激活函数一般用于神经网络的层与层之间，将上一层的输出转换之后输入到下一层。如果没有激活函数引入的非线性特性，那么神经网络就只相当于原始感知机的矩阵相乘激活函数分为线性激活函数和非线性激活函数。</p>
<p>为什么需要非线性的激活函数：神经网络用于实现复杂的函数，而<font color="red"> 非线性激活函数能够使神经网络逼近任意复杂的函数</font>。如果没有激活函数引入的非线性，多层神经网络就相当于单层的神经网络。常用的非线性激活函数有sigmod, tanh, relu, lrelu, prelu, swish等。</p>
<h2 id="1-sigmoid"><a href="#1-sigmoid" class="headerlink" title="1. sigmoid"></a>1. sigmoid</h2><p>Sigmoid也被称为逻辑激活函数(Logistic Activation Function)。它将一个实数值压缩到0至1的范围内。当我们的最终目标是预测概率时，它可以被应用到输出层。它使很大的负数向0转变，很大的正数向1转变。在数学上表示为：</p>
<p><img src="https://i.loli.net/2020/08/30/NEtnpfRKQUYsCJ7.gif" alt="1.gif"></p>
<p>下图为sigmoid函数以及它的导数图像。</p>
<p><img src="https://i.loli.net/2020/08/30/qdMyYbTGVvPteXn.png" alt="2.png"></p>
<h3 id="Sigmoid激活函数的三个主要缺点是："><a href="#Sigmoid激活函数的三个主要缺点是：" class="headerlink" title="Sigmoid激活函数的三个主要缺点是："></a>Sigmoid激活函数的三个主要缺点是：</h3><ul>
<li><strong>梯度消失：</strong>sigmoid函数在0和1附近是平坦的。也就是说，sigmoid的梯度在0和1附近为0。在通过sigmoid函数网络反向传播时，当神经元的输出近似于0和1时它的梯度接近于0。这些神经元被称为饱和神经元。因此，这些神经元的权值无法更新。不仅如此，与这些神经元相连接的神经元的权值也更新得非常缓慢。<font color="red">函数的梯度值&lt;0.25,网络较深时，链式的反向传播导致梯度值非常小接近零, Grad=Error*Sigmoid`(x)*x，导致每经过一层Error都是成倍衰减，这个问题也被称为梯度消失。</font>所以，想象如果有一个大型网络包含有许多处于饱和动态的sigmoid激活函数的神经元，那么网络将会无法进行反向传播；</li>
<li><strong>输出不以0为中心</strong>：输出均值不为零。反向传播时后一层将得到上一层输出的非0均值作为输入，会出现偏移现象；Δw将全为正数、或全为负数，使得梯度下降过程中出现z字型下降，导致权值更新效率降低；</li>
<li><strong>计算量太大速度慢</strong>：指数函数与其它非线性激活函数相比计算量太大了，指数计算速度慢。</li>
</ul>
<h2 id="2-tanh"><a href="#2-tanh" class="headerlink" title="2. tanh"></a>2. tanh</h2><p>Tanh也被称为双曲正切激活函数。类似sigmoid，tanh也是把一个实数值压缩。与sigmoid不同的是，tanh在-1到1的输出范围内是零均值的。可以把tanh函数看做是两个sigmoid加在一起: tanh(x)=sigmoid(2x)-1。</p>
<p><img src="https://i.loli.net/2020/08/30/U8r5kZC6zoxOsJD.png" alt="3.png"></p>
<p>在实际运用中，tanh比sigmoid更好。这主要是因为Sigmoid函数在输入处于[-1,1]之间时，函数值变化敏感，一旦接近或者超出区间就失去敏感性，处于饱和状态，影响神经网络预测的精度值。而tanh的输出和输入能够保持非线性单调上升和下降关系，符合BP网络的梯度求解，容错性好，有界，渐进于0、1，符合人脑神经饱和的规律，<font color="red">与 sigmoid 的区别是，tanh 输出是 0 均值的</font>，因此实际应用中 tanh 会比 sigmoid 更好。</p>
<font color="red"><strong>Tanh唯一的缺点是</strong>：tanh函数也存在着梯度消失的问题，因此在饱和时会导致梯度消失。</font>

<p><img src="https://i.loli.net/2020/08/30/poTEfgAb2wi6z1e.png" alt="1.png"></p>
<h2 id="3-线性整流函数（ReLU）"><a href="#3-线性整流函数（ReLU）" class="headerlink" title="3. 线性整流函数（ReLU）"></a>3. 线性整流函数（ReLU）</h2><p>ReLU是目前应用最为广泛的激活函数。 该函数以0为分界线，输入小于0的部分输出均为0，大于等于0的部分输出等于输入值。</p>
<p>ReLU及其导数的表达式：</p>
<p><img src="https://i.loli.net/2020/08/30/AVC16sm5rzx9Pij.gif" alt="1.gif"></p>
<p><img src="https://i.loli.net/2020/08/30/EgxudmY3SzCPZsi.png" alt="4.png"></p>
<p><strong>ReLU的优点：</strong><font color="red">收敛速度快；至少在正数范围内没有饱和,能够对梯度消失有抵抗能力； 因为它是使用简单的阈值，在计算上非常有效率。</font></p>
<ul>
<li>ReLU的导数不是常数，所以ReLU是非线性的。<strong>Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生</strong>。</li>
<li>ReLu虽然在大于0的区间是线性的，在小于等于0的部分也是线性的，但是它<strong>整体不是线性的</strong>，因为不是一条直线，所以Relu函数是非线性函数。</li>
</ul>
<p><strong>ReLU的缺点：</strong></p>
<ul>
<li>输出不以0为中心</li>
<li>对于ReLu中(x&lt;0)的激活，此时梯度为0，因此在下降过程中权重不会被调整。其不会在任何数据点上再次激活。简单地说，ReLu可能导致神经元死亡。</li>
</ul>
<h2 id="4-泄漏ReLU激活函数-Leaky-ReLU"><a href="#4-泄漏ReLU激活函数-Leaky-ReLU" class="headerlink" title="4. 泄漏ReLU激活函数(Leaky ReLU)"></a>4. 泄漏ReLU激活函数(Leaky ReLU)</h2><p>为了解决ReLU中容易出现死神经元的问题，对负数部分进行修正，加入一个小的斜率（ɑ∈(0,1)，一般取0.1、0.01等）使得负数输入不会全部被稀疏掉.</p>
<p><img src="https://i.loli.net/2020/08/30/dbxKNlqBsIozXyh.png" alt="1.png"></p>
<p>还有许多对ReLU改进的激活函数：PReLU、ELU、SELU等。</p>
<h1 id="二、-过拟合问题"><a href="#二、-过拟合问题" class="headerlink" title="二、 过拟合问题"></a>二、 过拟合问题</h1><h2 id="过拟合产生的原因"><a href="#过拟合产生的原因" class="headerlink" title="过拟合产生的原因"></a>过拟合产生的原因</h2><ol>
<li><p><strong>数据不足，无法拟合数据的真实分布</strong>。</p>
<ul>
<li>数据有噪声；</li>
<li>训练数据不足，有限的训练数据。</li>
</ul>
</li>
<li><p><strong>模型复杂</strong></p>
<ul>
<li><strong>模型假设过于复杂，参数过多，训练数据不足、噪声过多</strong>，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。 过度的拟合了训练数据，而没有考虑到泛化能力</li>
<li><strong>训练模型过度</strong>：权值学习迭代次数足够多(Overtraining),拟合了训练数据中的噪声和训练样例中没有代表性的特征</li>
</ul>
</li>
</ol>
<h2 id="过拟合的解决方法"><a href="#过拟合的解决方法" class="headerlink" title="过拟合的解决方法"></a>过拟合的解决方法</h2><ol>
<li>从数据角度解决过拟合<ul>
<li>获取更多数据 ：从数据源头获取更多数据；数据增强（Data Augmentation）；</li>
<li>数据处理和清洗(data ckeaning/Pruning)：将错误的label 纠正或者删除错误的数据。</li>
</ul>
</li>
<li>从模型角度解决过拟合<ul>
<li>正则化</li>
<li>Dropout</li>
<li>提前停止（early stopping）</li>
</ul>
</li>
</ol>
<h2 id="网络正则化"><a href="#网络正则化" class="headerlink" title="网络正则化"></a>网络正则化</h2><p>机器学习模型的关键是泛化问题，即在样本真实分布上的期望风险最小化。<br>而训练数据集上的经验风险最小化和期望风险并不一致。由于神经网络的拟合<br>能力非常强，其在训练数据上的错误率往往都可以降到非常低，甚至可以到0，<br>从而导致过拟合。因此，如何提高神经网络的泛化能力反而成为影响模型能力<br>的最关键因素。</p>
<p>在传统的机器学习中，<font color="red">提高泛化能力的方法主要是限制模型复杂度</font>，比如采<br>用ℓ1 和ℓ2 正则化等方式。而在训练深层神经网络时，特别是在过度参数（Over-<br>Parameterized）时，ℓ1 和ℓ2 正则化的效果往往不如浅层机器学习模型中显著。<br>因此训练深度学习模型时，往往还会使用其它的正则化方法，比如数据增强、提前停止、丢弃法、集成法等。</p>
<h3 id="ℓ1和ℓ2正则化"><a href="#ℓ1和ℓ2正则化" class="headerlink" title="ℓ1和ℓ2正则化"></a>ℓ1和ℓ2正则化</h3><p>ℓ1 和ℓ2 正则化是机器学习中最常用的正则化方法，通过约束参数的ℓ1 和ℓ2<br>范数来减小模型在训练数据集上的过拟合现象。</p>
<p>通过加入ℓ1 和ℓ2 正则化，优化问题可以写为：</p>
<p><img src="https://i.loli.net/2020/08/31/12hWOjQLGVJs45v.png" alt="1.png"></p>
<p>其中 L(·) 为损失函数，N 为训练样本数量，f(·) 为待学习的神经网络，θ 为其参<br>数，ℓp 为范数函数，p 的取值通常为{1, 2} 代表ℓ1 和ℓ2 范数，λ 为正则化系数。</p>
<p><img src="https://i.loli.net/2020/08/31/pq2XEfF9NebSVA6.png" alt="2.png"></p>
<p>正则化之所以能够降低过拟合的原因在于，正则化是结构风险最小化的一种策略实现。</p>
<p>给loss function加上正则化项，能使得新得到的优化目标函数h = f+normal，需要在f和normal中做一个权衡（trade-off），如果还像原来只优化f的情况下，那可能得到一组解比较复杂，使得正则项normal比较大，那么h就不是最优的，因此可以看出加正则项能让解更加简单，符合奥卡姆剃刀理论，同时也比较符合在偏差和方差（方差表示模型的复杂度）分析中，通过降低模型复杂度，得到更小的泛化误差，降低过拟合程度。</p>
<h4 id="ℓ1和ℓ2正则化的区别"><a href="#ℓ1和ℓ2正则化的区别" class="headerlink" title="ℓ1和ℓ2正则化的区别"></a>ℓ1和ℓ2正则化的区别</h4><p>ℓ1 正则化就是在 loss function 后边所加正则项为 ℓ1 范数，<font color="red">加上 ℓ1 范数容易得到稀疏解（0 比较多），能够实现特征的自动选择</font>。ℓ2 正则化就是 loss function 后边所加正则项为 ℓ2 范数的平方，<font color="red">加上 ℓ2 正则相比于 ℓ1 正则来说，得到的解比较平滑（不是稀疏），但是同样能够保证解中接近于 0（但不是等于 0，所以相对平滑）的维度比较多，降低模型的复杂度。</font></p>
<p><strong>ℓ1正则比ℓ2正则化获得稀疏解的原因：</strong></p>
<p><img src="https://i.loli.net/2020/08/31/Cx7B4Ajdn5esISO.jpg" alt="1.jpg"></p>
<p><img src="https://i.loli.net/2020/08/31/6FW2U7H4YDA5vjx.jpg" alt="2.jpg"></p>
<p><img src="https://i.loli.net/2020/08/31/NSEPmsz3t9DlLVR.jpg" alt="3.jpg"></p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><h1 id="三、梯度爆炸和梯度消失"><a href="#三、梯度爆炸和梯度消失" class="headerlink" title="三、梯度爆炸和梯度消失"></a>三、梯度爆炸和梯度消失</h1><h2 id="1-产生原因"><a href="#1-产生原因" class="headerlink" title="1. 产生原因"></a>1. 产生原因</h2><h3 id="梯度消失原因"><a href="#梯度消失原因" class="headerlink" title="梯度消失原因"></a>梯度消失原因</h3><ul>
<li><p>深度神经网络角度：网络层数多</p>
</li>
<li><p>激活函数角度：选择不合适的激活函数。e.g., sigmoid,tanh。</p>
<h3 id="梯度爆炸原因"><a href="#梯度爆炸原因" class="headerlink" title="梯度爆炸原因"></a>梯度爆炸原因</h3></li>
<li><p>深度神经网络角度：网络层数多</p>
</li>
<li><p>参数初始值过大</p>
</li>
</ul>
<p>梯度消失/爆炸的根源—–深度神经网络和反向传播。 目前优化神经网络的方法都是基于反向传播的思想，即根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。</p>
<p><img src="https://i.loli.net/2020/09/01/upy9Tr4ImUO3Sht.jpg" alt="1.jpg"></p>
<p>上图是一个5层的网络，设最终的损失函数为L，则利用反向传播方法求L关于w1的梯度过程如下：</p>
<p><img src="https://i.loli.net/2020/09/01/Fe4pAbNzEXuPmxQ.png" alt="1.png"></p>
<p>在上述梯度反向传播的过程中，若权重参数初始值较小 |w|&lt;1，随着网络层数的加深，梯度一直在衰减，使得浅层网络的参数的梯度接近于0，产生梯度消失，这时网络层数较深的原因；另外，若网络中选择sigmoid作为激活函数，而sigmoid的导数值&lt;0.25, 链式的导数相乘中随着网络加深梯度的值快速衰减为0，这时选择了不合适的激活函数所致。</p>
<p>而当权重参数初始值比较大 |w|&gt;1,梯度随着网络的深度的增加，使得参数的梯度非常大，长生梯度爆炸。</p>
<h2 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2. 解决方法"></a>2. 解决方法</h2><h3 id="梯度爆炸的解决方法"><a href="#梯度爆炸的解决方法" class="headerlink" title="梯度爆炸的解决方法"></a>梯度爆炸的解决方法</h3><h5 id="1）使用梯度剪切预防梯度爆炸"><a href="#1）使用梯度剪切预防梯度爆炸" class="headerlink" title="1）使用梯度剪切预防梯度爆炸"></a>1）使用梯度剪切预防梯度爆炸</h5><p>梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。</p>
<h5 id="2）权重正则化"><a href="#2）权重正则化" class="headerlink" title="2）权重正则化"></a>2）权重正则化</h5><p>比较常见的是l1正则，和l2正则。</p>
<h3 id="梯度消失的解决方法"><a href="#梯度消失的解决方法" class="headerlink" title="梯度消失的解决方法"></a>梯度消失的解决方法</h3><h5 id="1）-使用relu、leakrelu、elu等激活函数"><a href="#1）-使用relu、leakrelu、elu等激活函数" class="headerlink" title="1） 使用relu、leakrelu、elu等激活函数"></a>1） 使用relu、leakrelu、elu等激活函数</h5><h5 id="2）-batchnorm"><a href="#2）-batchnorm" class="headerlink" title="2） batchnorm"></a>2） batchnorm</h5><p>Batchnorm就是通过对每一层的输出做scale和shift的方法，通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到接近均值为0方差为1的标准正太分布，即严重偏离的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，使得让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</p>
<h5 id="3）-残差连接"><a href="#3）-残差连接" class="headerlink" title="3） 残差连接"></a>3） 残差连接</h5><h5 id="4）-LSTM"><a href="#4）-LSTM" class="headerlink" title="4） LSTM"></a>4） LSTM</h5><h1 id="四、-归一化"><a href="#四、-归一化" class="headerlink" title="四、 归一化"></a>四、 归一化</h1><h1 id="五、-优化器"><a href="#五、-优化器" class="headerlink" title="五、 优化器"></a>五、 优化器</h1><p>目前，深层神经网络的参数学习主要是通过梯度下降方法来寻找一组可以最小化结构风险的参数。在具体实现中，梯度下降法可以分为：批量梯度下降、随机梯度下降以及小批量梯度下降三种形式。</p>
<h2 id="BGD-批量梯度下降"><a href="#BGD-批量梯度下降" class="headerlink" title="BGD(批量梯度下降)"></a>BGD(批量梯度下降)</h2><p><strong>BGD（批量梯度下降，这里的批量实际上是全部数据）</strong>每次迭代采用整个训练集数据来计算损失函数 J(θ)对参数 θ 的的梯度。</p>
<p><img src="https://i.loli.net/2020/09/02/MTROQX4E8se62q9.png" alt="1.png"></p>
<font color="red"><strong>缺点：</strong></font> 

<p>在训练深层神经网络时，训练数据的规模比较大。如果在梯度下降时，<font color="red">每次迭代都要计算整个训练数据上的梯度需要比较多的计算资源，计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。</font> 此外，<font color="red">大规模训练集中的数据通常也会非常冗余，也没有必要在整个训练集上计算梯度。</font></p>
<h2 id="SGD-随机梯度下降"><a href="#SGD-随机梯度下降" class="headerlink" title="SGD(随机梯度下降)"></a>SGD(随机梯度下降)</h2><p>和 BGD 的一次用所有数据计算梯度相比，SGD 每次更新时对每个样本进行梯度更新，对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余，而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。</p>
<p><img src="https://i.loli.net/2020/09/02/YfUyPA7RJSDETlG.png" alt="2.png"></p>
<font color="red"><strong>缺点：</strong></font>   

<font color="red">SGD 因为更新比较频繁，带有随机性，会造成 cost function 有严重的震荡。</font><br>SGD的噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。所以虽然训练速度快，但是准确度下降，并不是全局最优。<br><br>## MBGD(最小批量梯度下降)<br><br>MBGD 每一次利用一小批样本，即 n 个样本进行计算，这样它可以降低参数更新时的方差，收敛更稳定，另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。<br><br><img src="https://i.loli.net/2020/09/02/B3YTswv6rIRmkgx.png" alt="3.png"><br><br><font color="red"><strong>缺点：</strong></font>  

<font color="red">不能保证很好的收敛性，learning rate 如果选择的太小，收敛速度会很慢，如果太大，损失函数就会在极小值处不停地震荡甚至偏离。</font>（有一种措施是先设定大一点的学习率，当两次迭代之间的变化低于某个阈值后，就减小 learning rate，不过这个阈值的设定需要提前写好，这样的话就不能够适应数据集的特点。）<br><br><strong>为了更有效地进行训练深层神经网络，在标准的小批量梯度下降方法的基础上，也经常使用一些改进方法以加快优化速度。<font color="red">常见的改进方法主要从以下两个方面进行改进：学习率衰减和梯度方向优化。</font></strong><br><br>## 改进一：调整学习率<br><br>在梯度下降中，学习率α 的取值非常关键，如果过大就不会收敛，如果过小则收敛速度太慢。<font color="red">从经验上看，学习率在一开始要保持大些来保证收敛速度，在收敛到最优点附近时要小些以避免来回震荡。因此，比较简单直接的学习率调整可以通过学习率衰减（Learning Rate Decay）的方式来实现。</font>

<p>除了采用如指数衰减等这些固定衰减率的调整学习率方法外，还有些自适应地调整学习率的方法，比如AdaGrad、RMSprop、AdaDelta 等。这些方法都对每个参数设置不同的学习率。</p>
<h3 id="AdGrad"><a href="#AdGrad" class="headerlink" title="AdGrad"></a>AdGrad</h3><p>AdaGrad（Adaptive Gradient）算法是借鉴L2 正则化的思想，每次迭代时自适应地调整每个参数的学习率。在第t 迭代时，先计算每个参数梯度平方的累计值：</p>
<p><img src="https://i.loli.net/2020/09/02/awIjbMrRfnByQHh.jpg" alt="1.JPG"></p>
<p>AdaGrad 算法的参数更新差值为：</p>
<p><img src="https://i.loli.net/2020/09/02/DkGuIAbhUWjrgax.jpg" alt="2.JPG"></p>
<p>Adagrad 算法的缺点是在经过一定次数的迭代依然没有找到最优点时，由<br>于这时的学习率已经非常小，很难再继续找到最优点。</p>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>RMSprop算法是Geoff Hinton 提出的一种自适应学习率的方法，可以在有些情况下避免AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点。</p>
<p>RMSprop算法首先计算每次迭代梯度gt 平方的指数衰减移动平均：</p>
<p><img src="https://i.loli.net/2020/09/02/EC3GuotRWnf21cg.jpg" alt="3.JPG"></p>
<p>RMSprop算法的参数更新差值为：</p>
<p><img src="https://i.loli.net/2020/09/02/L379Uox5RwaBqN8.jpg" alt="4.JPG"></p>
<p>从上式可以看出，RMSProp 算法和Adagrad 算法的区别在于Gt 的计算由累积方式变成了指数衰减移动平均。在迭代过程中，每个参数的学习率并不是呈衰减趋势，既可以变小也可以变大。</p>
<h2 id="改进二：梯度方向优化"><a href="#改进二：梯度方向优化" class="headerlink" title="改进二：梯度方向优化"></a>改进二：梯度方向优化</h2><p>除了调整学习率之外，还可以通过使用最近一段时间内的平均梯度来代替当前时刻的梯度来作为参数更新的方向。在小批量梯度下降中，如果每次选取样本数量比较小，损失会呈现震荡的方式下降。<font color="red">有效地缓解梯度下降中的震荡的方式是通过用梯度的移动平均来代替每次的实际梯度，并提高优化速度，这就是动量法。</font>  </p>
<h3 id="Momentum-动量法"><a href="#Momentum-动量法" class="headerlink" title="Momentum (动量法)"></a>Momentum (动量法)</h3><p>动量是模拟物理中的概念。一般而言，一个物体的动量指的是这个物体在它运动方向上保持运动的趋势，是物体的质量和速度的乘积。动量法是用之前积累动量来替代真正的梯度。每次<br>迭代的梯度可以看作是加速度。</p>
<p>在第t 次迭代时，计算负梯度的“加权移动平均”作为参数的更新方向，</p>
<p><img src="https://i.loli.net/2020/09/02/fIHqC2zTM7x5wPS.jpg" alt="5.JPG"></p>
<p>通过动量法，<font color="red">每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值。</font>当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用。一般而言，在迭代初期，梯度方法都比较一致，动量法会起到加速作用，可以更快地到达最优点。<font color="red">在迭代后期，梯度方法会取决不一致，在收敛值附近震荡，动量法会起到减速作用，增加稳定性。</font>从某种角度来说，当前梯度叠加上部分的上次梯度，一定程度上可以近似看作二阶梯度。</p>
<h3 id="Adam（动量法-RMSprop）"><a href="#Adam（动量法-RMSprop）" class="headerlink" title="Adam（动量法 + RMSprop）"></a>Adam（动量法 + RMSprop）</h3><p>自适应动量估计（Adaptive Moment Estimation，Adam）算法可以看作是动量法和RMSprop 的结合，不但使用动量作为参数更新方向，而且可以自适应调整学习率。</p>
<p>Adam 算法一方面计算梯度平方 gt^2 的指数加权平均（和 RMSprop 类似），另一方面计算梯度gt 的指数加权平均（和动量法类似:</p>
<p><img src="https://i.loli.net/2020/09/02/28L71Nvd3e49ruW.jpg" alt="6.JPG"></p>
<p>其中β1 和β2 分别为两个移动平均的衰减率，通常取值为β1 = 0.9, β2 = 0.99。</p>
<p>假设M0 = 0,G0 = 0，那么在迭代初期 Mt 和 Gt 的值会比真实的均值和方差要小。特别是当 β1 和 β2 都接近于1 时，偏差会很大。因此，需要对偏差进行修正。</p>
<p><img src="https://i.loli.net/2020/09/02/UW9ZKE6VrIxFeGH.jpg" alt="7.JPG"></p>
<p>Adam算法的参数更新差值为:</p>
<p><img src="https://i.loli.net/2020/09/02/2lBrUymeFPhcOZx.jpg" alt="8.JPG"></p>
<h1 id="六、数据预处理"><a href="#六、数据预处理" class="headerlink" title="六、数据预处理"></a>六、数据预处理</h1><h2 id="归一化方法"><a href="#归一化方法" class="headerlink" title="归一化方法"></a>归一化方法</h2><h3 id="缩放归一化"><a href="#缩放归一化" class="headerlink" title="缩放归一化"></a>缩放归一化</h3><p>缩放归一化是一种非常简单的归一化方法，通过缩放将每一个特征的取值范围归一到[0, 1] 或[−1, 1] 之间。对于每一维特征x，</p>
<p><img src="https://i.loli.net/2020/09/02/kmWcP7lV4tXRCrU.jpg" alt="9.JPG"></p>
<h3 id="标准归一化"><a href="#标准归一化" class="headerlink" title="标准归一化"></a>标准归一化</h3><p>标准归一化也叫 z-score 归一化，来源于统计上的标准分数。将每一个维特征都处理为符合标准正态分布（均值为0，标准差为1）。假设有N 个样本{x^(i)}, i=1, · · · ,N，对于每一维特征x，我们先计算它的均值和标准差：</p>
<p><img src="https://i.loli.net/2020/09/02/XsW42vmVzyZFauj.jpg" alt="10.JPG"></p>
<p>特征减去均值初一标准差，得到新的特征值：</p>
<p><img src="https://i.loli.net/2020/09/02/NHEPoCLqW4VkUKv.jpg" alt="11.JPG"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/08/23/数据结构与算法-排序算法总结/" rel="next" title="数据结构与算法-排序算法总结">
                <i class="fa fa-chevron-left"></i> 数据结构与算法-排序算法总结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/09/04/推荐系统-传统的推荐算法总结/" rel="prev" title="推荐系统-传统的推荐算法总结">
                推荐系统-传统的推荐算法总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="guoLipa" />
            
              <p class="site-author-name" itemprop="name">guoLipa</p>
              <p class="site-description motion-element" itemprop="description">Internet of things</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/guolipa" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="2813281589@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/p/1005053994861822/home?from=page_100505&mod=TAB&is_all=1#place" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/sinat_41847989" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-cc"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一、常用的激活函数"><span class="nav-number">1.</span> <span class="nav-text">一、常用的激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-sigmoid"><span class="nav-number">1.1.</span> <span class="nav-text">1. sigmoid</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid激活函数的三个主要缺点是："><span class="nav-number">1.1.1.</span> <span class="nav-text">Sigmoid激活函数的三个主要缺点是：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-tanh"><span class="nav-number">1.2.</span> <span class="nav-text">2. tanh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-线性整流函数（ReLU）"><span class="nav-number">1.3.</span> <span class="nav-text">3. 线性整流函数（ReLU）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-泄漏ReLU激活函数-Leaky-ReLU"><span class="nav-number">1.4.</span> <span class="nav-text">4. 泄漏ReLU激活函数(Leaky ReLU)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二、-过拟合问题"><span class="nav-number">2.</span> <span class="nav-text">二、 过拟合问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合产生的原因"><span class="nav-number">2.1.</span> <span class="nav-text">过拟合产生的原因</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合的解决方法"><span class="nav-number">2.2.</span> <span class="nav-text">过拟合的解决方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络正则化"><span class="nav-number">2.3.</span> <span class="nav-text">网络正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ℓ1和ℓ2正则化"><span class="nav-number">2.3.1.</span> <span class="nav-text">ℓ1和ℓ2正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ℓ1和ℓ2正则化的区别"><span class="nav-number">2.3.1.1.</span> <span class="nav-text">ℓ1和ℓ2正则化的区别</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dropout"><span class="nav-number">2.4.</span> <span class="nav-text">Dropout</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三、梯度爆炸和梯度消失"><span class="nav-number">3.</span> <span class="nav-text">三、梯度爆炸和梯度消失</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-产生原因"><span class="nav-number">3.1.</span> <span class="nav-text">1. 产生原因</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失原因"><span class="nav-number">3.1.1.</span> <span class="nav-text">梯度消失原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度爆炸原因"><span class="nav-number">3.1.2.</span> <span class="nav-text">梯度爆炸原因</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-解决方法"><span class="nav-number">3.2.</span> <span class="nav-text">2. 解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度爆炸的解决方法"><span class="nav-number">3.2.1.</span> <span class="nav-text">梯度爆炸的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1）使用梯度剪切预防梯度爆炸"><span class="nav-number">3.2.1.0.1.</span> <span class="nav-text">1）使用梯度剪切预防梯度爆炸</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2）权重正则化"><span class="nav-number">3.2.1.0.2.</span> <span class="nav-text">2）权重正则化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失的解决方法"><span class="nav-number">3.2.2.</span> <span class="nav-text">梯度消失的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1）-使用relu、leakrelu、elu等激活函数"><span class="nav-number">3.2.2.0.1.</span> <span class="nav-text">1） 使用relu、leakrelu、elu等激活函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2）-batchnorm"><span class="nav-number">3.2.2.0.2.</span> <span class="nav-text">2） batchnorm</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3）-残差连接"><span class="nav-number">3.2.2.0.3.</span> <span class="nav-text">3） 残差连接</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4）-LSTM"><span class="nav-number">3.2.2.0.4.</span> <span class="nav-text">4） LSTM</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#四、-归一化"><span class="nav-number">4.</span> <span class="nav-text">四、 归一化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#五、-优化器"><span class="nav-number">5.</span> <span class="nav-text">五、 优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#BGD-批量梯度下降"><span class="nav-number">5.1.</span> <span class="nav-text">BGD(批量梯度下降)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SGD-随机梯度下降"><span class="nav-number">5.2.</span> <span class="nav-text">SGD(随机梯度下降)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AdGrad"><span class="nav-number">5.2.1.</span> <span class="nav-text">AdGrad</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RMSprop"><span class="nav-number">5.2.2.</span> <span class="nav-text">RMSprop</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#改进二：梯度方向优化"><span class="nav-number">5.3.</span> <span class="nav-text">改进二：梯度方向优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Momentum-动量法"><span class="nav-number">5.3.1.</span> <span class="nav-text">Momentum (动量法)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam（动量法-RMSprop）"><span class="nav-number">5.3.2.</span> <span class="nav-text">Adam（动量法 + RMSprop）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#六、数据预处理"><span class="nav-number">6.</span> <span class="nav-text">六、数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#归一化方法"><span class="nav-number">6.1.</span> <span class="nav-text">归一化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#缩放归一化"><span class="nav-number">6.1.1.</span> <span class="nav-text">缩放归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#标准归一化"><span class="nav-number">6.1.2.</span> <span class="nav-text">标准归一化</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">guoLipa</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
